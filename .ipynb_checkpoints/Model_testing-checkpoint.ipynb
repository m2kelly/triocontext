{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparison\n",
    "\n",
    "This notebook computes the loglikelihood for a given kmer model and the AIC based on the number of parameters.\n",
    "\n",
    "---\n",
    "\n",
    "## Output\n",
    "\n",
    "Several files in the form of *model.txt*, containing the loglikelihood and the number of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "\n",
    "Files in **data** directory.\n",
    "\n",
    "- *kmer_freq_file*: file that contains the counts of k-mers.\n",
    "\n",
    "Files in **non_provided_data/mutations** directory.\n",
    "\n",
    "- *germinal_ultimate_dataset.bed.gz*: file containing the mutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import tabix  # package pytabix\n",
    "import pybedtools\n",
    "from bgreference import hg19\n",
    "import gzip, pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "All the functions needed for this notebook are coded below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_version_ensembl(x, colname):\n",
    "    \"\"\"\n",
    "    Remove version from the ensembl ID\n",
    "\n",
    "    Args:\n",
    "        x: dataframe row\n",
    "        colname: column name\n",
    "\n",
    "    Returns:\n",
    "        str. Text before a '.'\n",
    "\n",
    "    \"\"\"\n",
    "    ensembl_id = x[colname]\n",
    "    ensembl_id_only = ensembl_id.split('.')[0]\n",
    "\n",
    "    return ensembl_id_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_likelihood(k, mutation_df, middle_exon_coords, signatures_file, middle_distance_threshold):\n",
    "    \n",
    "    nucleotides = set(['A', 'T', 'C', 'G'])\n",
    "    \n",
    "    # Process signatures\n",
    "    all_signatures = pd.read_csv(signatures_file, sep='\\t')\n",
    "    name = 'Probability_germinal'\n",
    "    sub_signatures_df = all_signatures[['mutation', name]]\n",
    "    prob_dict = sub_signatures_df.set_index('mutation')[name].T.to_dict()\n",
    "    \n",
    "    # Add probability of no mutation\n",
    "    for my_kmer in kmer_generator('ACGT',k):\n",
    "        my_ref_base = my_kmer[(k//2):(k//2)+1].upper()\n",
    "        my_alt_bases = list(nucleotides - set(my_ref_base)) #The rest are alternative ones\n",
    "        my_key1 = str((my_kmer , my_kmer[0:(k//2)] + my_alt_bases[0] + my_kmer[(k//2)+1:]))\n",
    "        my_key2 = str((my_kmer , my_kmer[0:(k//2)] + my_alt_bases[1] + my_kmer[(k//2)+1:]))\n",
    "        my_key3 = str((my_kmer , my_kmer[0:(k//2)] + my_alt_bases[2] + my_kmer[(k//2)+1:]))\n",
    "        new_key = str((my_kmer , my_kmer))\n",
    "        prob_dict[new_key] = 1 - prob_dict[my_key1] - prob_dict[my_key2] - prob_dict[my_key3]\n",
    "    \n",
    "    # Process coordinates\n",
    "    middle_exon_coords['exon_size'] = (middle_exon_coords['end'] - middle_exon_coords['start'])\n",
    "    middle_exon_coords['exon_middle_start'] = (middle_exon_coords['start'] + middle_exon_coords['exon_size']/2)\n",
    "    middle_exon_coords['exon_middle_start'] = middle_exon_coords.apply(lambda x:\n",
    "                                                                    math.floor(x['exon_middle_start']),\n",
    "                                                                    axis=1)\n",
    "    \n",
    "    middle_exon_coords['exon_middle_end'] = middle_exon_coords['exon_middle_start'] + 1\n",
    "    middle_exon_coords['region_start'] = middle_exon_coords['exon_middle_start'] - middle_distance_threshold\n",
    "    middle_exon_coords['region_end'] = middle_exon_coords['exon_middle_end'] + middle_distance_threshold\n",
    "    sub_exons_coords = middle_exon_coords[['chr', 'region_start', 'region_end', 'ensembl', 'exon_size']]\n",
    "    \n",
    "    # Process mutations\n",
    "    sub_exons_coords_bed = pybedtools.BedTool.from_dataframe(sub_exons_coords)\n",
    "    mutations_bed = pybedtools.BedTool.from_dataframe(mutation_df)\n",
    "    my_bed = sub_exons_coords_bed.intersect(mutations_bed, wao=True)\n",
    "\n",
    "    mutations_in_range = pd.read_table(my_bed.fn, names = ['chr', 'region_start', 'region_end',\n",
    "                        'ensembl', 'exon_size', 'mut_chr', 'mut_start', 'mut_end', 'mut_ref', 'mut_alt',\n",
    "                        'mut_sample', 'mut_type', 'overlap_bp'],  sep=\"\\s+\", index_col=False)\n",
    "    mutations_in_range = mutations_in_range[mutations_in_range['overlap_bp'] != 0]\n",
    "    mutations_in_range = mutations_in_range[['mut_chr', 'mut_start', 'mut_end', 'mut_ref',\n",
    "                                             'mut_alt']].drop_duplicates()\n",
    "    mutations_in_range.columns = ['chr', 'start', 'end', 'ref', 'alt']\n",
    "    mutations_in_range['ref_kmer'] = mutations_in_range.apply(lambda x: hg19(x['chr'],\n",
    "                                                                            x['start']+1-(k//2),1+2*(k//2)), axis=1)\n",
    "    mutations_in_range['alt_kmer'] = mutations_in_range.apply(lambda x: compute_kmer_alt(x, k), axis=1)\n",
    "    mutations_in_range['mutation'] = list(zip(mutations_in_range.ref_kmer, mutations_in_range.alt_kmer))\n",
    "    mutations_in_range['coords'] = list(zip(mutations_in_range.chr, mutations_in_range.start))\n",
    "    mut_dict = mutations_in_range.set_index('coords')['mutation'].T.to_dict()\n",
    "    \n",
    "    log_ll = 0\n",
    "    \n",
    "    # For each exon, each row, each 2001-nt sequence\n",
    "    for my_row in sub_exons_coords.values.tolist():\n",
    "\n",
    "        ## Get coordinates\n",
    "        my_chr = my_row[0]\n",
    "        my_start = int(my_row[1])\n",
    "        my_end = int(my_row[2])\n",
    "        n_bases = my_end - my_start\n",
    "        \n",
    "        ## Get sequence.\n",
    "        my_exon_bases = hg19(my_chr, my_start+1-(k//2), size=n_bases+2*(k//2))\n",
    "        ## Divide sequences into kmers\n",
    "        my_kmers = [my_exon_bases[i:i+k] for i in range(len(my_exon_bases)-(k-1))]\n",
    "\n",
    "        for i in range(0,len(my_kmers)):\n",
    "            pos = my_start + i\n",
    "            try:\n",
    "                log_ll = log_ll + np.log(prob_dict[str(mut_dict[(my_chr, pos)])])\n",
    "            except:\n",
    "                log_ll = log_ll + np.log(prob_dict[str(tuple((my_kmers[i],my_kmers[i])))])\n",
    "\n",
    "    return(log_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_likelihood_CpG(k, mutation_df, middle_exon_coords, signatures_file, middle_distance_threshold):\n",
    "    \n",
    "    nucleotides = set(['A', 'T', 'C', 'G'])\n",
    "    \n",
    "    # Process signatures\n",
    "    all_signatures = pd.read_csv(signatures_file, sep='\\t')\n",
    "    name = 'Probability_germinal'\n",
    "    sub_signatures_df = all_signatures[['mutation', name]]\n",
    "    prob_dict = sub_signatures_df.set_index('mutation')[name].T.to_dict()\n",
    "    \n",
    "    # Add probability of no mutation (manually)\n",
    "    prob_dict[str(('A','A'))] = 1 - prob_dict[str(('A','C'))] - prob_dict[str(('A','G'))] - prob_dict[str(('A','T'))]\n",
    "    prob_dict[str(('T','T'))] = 1 - prob_dict[str(('T','C'))] - prob_dict[str(('T','G'))] - prob_dict[str(('T','A'))]\n",
    "    prob_dict[str(('CpG','CpG'))] = 1 - prob_dict[str(('CpG','T'))] - prob_dict[str(('CpG','G'))] - prob_dict[str(('CpG','A'))]\n",
    "    prob_dict[str(('GpC','GpC'))] = 1 - prob_dict[str(('GpC','A'))] - prob_dict[str(('GpC','C'))] - prob_dict[str(('GpC','T'))]\n",
    "    prob_dict[str(('nonCpG','nonCpG'))] = 1 - prob_dict[str(('nonCpG','T'))] - prob_dict[str(('nonCpG','G'))] - prob_dict[str(('nonCpG','A'))]\n",
    "    prob_dict[str(('nonGpC','nonGpC'))] = 1 - prob_dict[str(('nonGpC','A'))] - prob_dict[str(('nonGpC','C'))] - prob_dict[str(('nonGpC','T'))]\n",
    "    \n",
    "    # Process coordinates\n",
    "    middle_exon_coords['exon_size'] = (middle_exon_coords['end'] - middle_exon_coords['start'])\n",
    "    middle_exon_coords['exon_middle_start'] = (middle_exon_coords['start'] + middle_exon_coords['exon_size']/2)\n",
    "    middle_exon_coords['exon_middle_start'] = middle_exon_coords.apply(lambda x:\n",
    "                                                                    math.floor(x['exon_middle_start']),\n",
    "                                                                    axis=1)\n",
    "    \n",
    "    middle_exon_coords['exon_middle_end'] = middle_exon_coords['exon_middle_start'] + 1\n",
    "    middle_exon_coords['region_start'] = middle_exon_coords['exon_middle_start'] - middle_distance_threshold\n",
    "    middle_exon_coords['region_end'] = middle_exon_coords['exon_middle_end'] + middle_distance_threshold\n",
    "    sub_exons_coords = middle_exon_coords[['chr', 'region_start', 'region_end', 'ensembl', 'exon_size']]\n",
    "    \n",
    "    # Process mutations\n",
    "    sub_exons_coords_bed = pybedtools.BedTool.from_dataframe(sub_exons_coords)\n",
    "    mutations_bed = pybedtools.BedTool.from_dataframe(mutation_df)\n",
    "    my_bed = sub_exons_coords_bed.intersect(mutations_bed, wao=True)\n",
    "\n",
    "    mutations_in_range = pd.read_table(my_bed.fn, names = ['chr', 'region_start', 'region_end',\n",
    "                        'ensembl', 'exon_size', 'mut_chr', 'mut_start', 'mut_end', 'mut_ref', 'mut_alt',\n",
    "                        'mut_sample', 'mut_type', 'overlap_bp'],  sep=\"\\s+\", index_col=False)\n",
    "    mutations_in_range = mutations_in_range[mutations_in_range['overlap_bp'] != 0]\n",
    "    mutations_in_range = mutations_in_range[['mut_chr', 'mut_start', 'mut_end', 'mut_ref',\n",
    "                                             'mut_alt']].drop_duplicates()\n",
    "    mutations_in_range.columns = ['chr', 'start', 'end', 'ref', 'alt']\n",
    "    mutations_in_range['ref_kmer'] = mutations_in_range.apply(lambda x: hg19(x['chr'],\n",
    "                                                                            x['start']+1-(k//2),1+2*(k//2)), axis=1)\n",
    "    mutations_in_range[['pre', 'nt', 'post']] = mutations_in_range['ref_kmer'].apply(lambda x: pd.Series(list(x)))\n",
    "    mutations_in_range['site'] = mutations_in_range.apply(lambda x: compute_CpG_site(x), axis=1)\n",
    "    mutations_in_range['mutation'] = list(zip(mutations_in_range.site, mutations_in_range.alt))\n",
    "    mutations_in_range['coords'] = list(zip(mutations_in_range.chr, mutations_in_range.start))\n",
    "    mut_dict = mutations_in_range.set_index('coords')['mutation'].T.to_dict()\n",
    "    \n",
    "    log_ll = 0\n",
    "    \n",
    "    # For each exon, each row, each 2001-nt sequence\n",
    "    for my_row in sub_exons_coords.values.tolist():\n",
    "\n",
    "        ## Get coordinates\n",
    "        my_chr = my_row[0]\n",
    "        my_start = int(my_row[1])\n",
    "        my_end = int(my_row[2])\n",
    "        n_bases = my_end - my_start\n",
    "        \n",
    "        ## Get sequence.\n",
    "        my_exon_bases = hg19(my_chr, my_start+1-(k//2), size=n_bases+2*(k//2))\n",
    "        ## Divide sequences into kmers\n",
    "        my_kmers = [my_exon_bases[i:i+k] for i in range(len(my_exon_bases)-(k-1))]\n",
    "\n",
    "        for i in range(0,len(my_kmers)):\n",
    "            pos = my_start + i\n",
    "            site = compute_CpG_site_string(my_kmers[i])\n",
    "            try:\n",
    "                log_ll = log_ll + np.log(prob_dict[str(mut_dict[(my_chr, pos)])])\n",
    "            except:\n",
    "                log_ll = log_ll + np.log(prob_dict[str((site,site))])\n",
    "\n",
    "    return(log_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_AIC(log_likelihood, n_params):\n",
    "    return(2*n_params - 2*log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_muts(mut_data, IDs_list):\n",
    "    \"\"\"\n",
    "    Function that removes mutations from a data frame, only if the mutation matches and ID\n",
    "    and it is enclosed in the exon coordinates of the specific 2001-nt window.\n",
    "\n",
    "    Args:\n",
    "        mut_data: dataframe with columns \"range_chr range_start range_end ensembl region_size\n",
    "                    region_middle_start region_middle_end exon_start exon_end mut_chr mut_start\n",
    "                    mut_end mut_ref mut_alt mut_sample mut_type mut_ID overlap_bp\n",
    "        IDs_list: list of IDs that must be removed\n",
    "    Returns:\n",
    "        pandas data frame with mutations with the ID removed, they sould be removed only once if the IDs are repeated.\n",
    "\n",
    "    \"\"\"\n",
    "    rows_to_remove = []\n",
    "    for ID in IDs_list:\n",
    "        sub_frame = mut_data[mut_data['mut_ID'] == ID]\n",
    "        for index, row in sub_frame.iterrows():\n",
    "            if (row['exon_start'] <= row['mut_end'] and row['exon_end'] >= row['mut_end']):\n",
    "                rows_to_remove.append(index)\n",
    "    return(mut_data.drop(rows_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function was made for testing purposes:\n",
    "def countX(lst, x): \n",
    "    count = 0\n",
    "    for ele in lst: \n",
    "        if (ele == x): \n",
    "            count = count + 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function was made for testing purposes:\n",
    "def check_consequence_TEST(chromosome, start_coord, alt, tabix):\n",
    "    \"\"\"\n",
    "    Function that classifies a given exonic mutation into the VEP classification given\n",
    "    tabix file with predicted effect.\n",
    "\n",
    "    Args:\n",
    "        chromosome: chromosome coordinate\n",
    "        start_coord: coordinate of the mutation\n",
    "        alt: alternative nucleotide\n",
    "        tabix: tabix indexed file containing the information\n",
    "        rank_info: dictionary with all the types of predicted effect and if we classify them as synonymous or not.\n",
    "    Returns:\n",
    "        str. Class of mutation on VEP classification\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    my_chr = chromosome[3:]\n",
    "    effects = tabix.querys(\"{}:{}-{}\".format(my_chr, start_coord, start_coord))\n",
    "    for effect in effects:\n",
    "        if len(effect) < 6:\n",
    "            continue\n",
    "        if effect[3] == alt:\n",
    "            consequence = effect[5].rstrip('\\r')\n",
    "            return(consequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_consequence(chromosome, start_coord, alt, tabix, rank_info):\n",
    "    \"\"\"\n",
    "    Function that classifies a given exonic mutation into synonymous \n",
    "    or not given a rank info and a tabix file with predicted effect.\n",
    "\n",
    "    Args:\n",
    "        chromosome: chromosome coordinate\n",
    "        start_coord: coordinate of the mutation\n",
    "        alt: alternative nucleotide\n",
    "        tabix: tabix indexed file containing the predicted VEP classification effect for a given position and change.\n",
    "        rank_info: dictionary with all the types of predicted effect and if we classify them as synonymous or not.\n",
    "    Returns:\n",
    "        str. *synonymous* or *non_synonymous*\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    my_chr = chromosome[3:]\n",
    "    effects = tabix.querys(\"{}:{}-{}\".format(my_chr, start_coord, start_coord))\n",
    "    for effect in effects:\n",
    "        if len(effect) < 6:\n",
    "            continue\n",
    "        if effect[3] == alt:\n",
    "            consequence = effect[5].rstrip('\\r')\n",
    "            try:\n",
    "                con = rank_info[consequence]\n",
    "                return(con)\n",
    "            except:\n",
    "                return('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def synonymous_or_not(x):\n",
    "    \"\"\"\n",
    "    Classifies consequence types between synonymous and non synonymous\n",
    "    using the RANK column\n",
    "\n",
    "    Args:\n",
    "        x: dataframe row\n",
    "\n",
    "    Returns:\n",
    "        str. *synonymous* or *non_synonymous*\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    my_rank = x['RANK']\n",
    "\n",
    "    if my_rank < 15:\n",
    "        my_consequence = 'non_synonymous'\n",
    "\n",
    "    else:\n",
    "        my_consequence = 'synonymous'\n",
    "\n",
    "    return my_consequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_likelihood_excluding(k, mutation_df, exon_coords, signatures_file, middle_distance_threshold, include):\n",
    "    \n",
    "    nucleotides = set(['A', 'T', 'C', 'G'])\n",
    "    \n",
    "    middle_exon_coords = exon_coords.copy(deep=True)\n",
    "    \n",
    "    # Process signatures\n",
    "    all_signatures = pd.read_csv(signatures_file, sep='\\t')\n",
    "    name = 'Probability_germinal'\n",
    "    sub_signatures_df = all_signatures[['mutation', name]]\n",
    "    prob_dict = sub_signatures_df.set_index('mutation')[name].T.to_dict()\n",
    "    \n",
    "    # Add probability of no mutation\n",
    "    for my_kmer in kmer_generator('ACGT',k):\n",
    "        my_ref_base = my_kmer[(k//2):(k//2)+1].upper()\n",
    "        my_alt_bases = list(nucleotides - set(my_ref_base)) #The rest are alternative ones\n",
    "        my_key1 = str((my_kmer , my_kmer[0:(k//2)] + my_alt_bases[0] + my_kmer[(k//2)+1:]))\n",
    "        my_key2 = str((my_kmer , my_kmer[0:(k//2)] + my_alt_bases[1] + my_kmer[(k//2)+1:]))\n",
    "        my_key3 = str((my_kmer , my_kmer[0:(k//2)] + my_alt_bases[2] + my_kmer[(k//2)+1:]))\n",
    "        new_key = str((my_kmer , my_kmer))\n",
    "        prob_dict[new_key] = 1 - prob_dict[my_key1] - prob_dict[my_key2] - prob_dict[my_key3]\n",
    "    \n",
    "    # Convert exonic coordinates into bed to intersect values\n",
    "    exon_coords_bed = pybedtools.BedTool.from_dataframe(middle_exon_coords)\n",
    "    \n",
    "    # Process coordinates\n",
    "    middle_exon_coords['exon_size'] = (middle_exon_coords['end'] - middle_exon_coords['start'])\n",
    "    middle_exon_coords['exon_middle_start'] = (middle_exon_coords['start'] + middle_exon_coords['exon_size']/2)\n",
    "    middle_exon_coords['exon_middle_start'] = middle_exon_coords.apply(lambda x:\n",
    "                                                                    math.floor(x['exon_middle_start']),\n",
    "                                                                    axis=1)\n",
    "    \n",
    "    middle_exon_coords['exon_middle_end'] = middle_exon_coords['exon_middle_start'] + 1\n",
    "    middle_exon_coords['region_start'] = middle_exon_coords['exon_middle_start'] - middle_distance_threshold\n",
    "    middle_exon_coords['region_end'] = middle_exon_coords['exon_middle_end'] + middle_distance_threshold\n",
    "    region_coords = middle_exon_coords[['chr', 'region_start', 'region_end', 'ensembl', 'exon_size', 'start', 'end']]\n",
    "    region_coords_bed = pybedtools.BedTool.from_dataframe(region_coords)\n",
    "    \n",
    "    # Process mutations\n",
    "    mutations_bed = pybedtools.BedTool.from_dataframe(mutation_df)\n",
    "    my_bed = region_coords_bed.intersect(mutations_bed, wao=True)\n",
    "    \n",
    "    # Filter mutations by the full region of interest\n",
    "    mutations_in_range = pd.read_table(my_bed.fn, names = ['chr', 'region_start', 'region_end',\n",
    "                        'ensembl', 'exon_size', 'exon_start', 'exon_end', 'mut_chr', 'mut_start', 'mut_end', 'mut_ref', 'mut_alt',\n",
    "                        'mut_sample', 'mut_type', 'mut_ID', 'overlap_bp'],  sep=\"\\s+\", index_col=False)\n",
    "    mutations_in_range = mutations_in_range[mutations_in_range['overlap_bp'] != 0]\n",
    "    \n",
    "    \n",
    "    # Filter mutations by the exonic regions\n",
    "    my_bed2 = exon_coords_bed.intersect(mutations_bed, wao=True)\n",
    "    mutations_in_range2 = pd.read_table(my_bed2.fn, names = ['exon_chr', 'exon_start', 'exon_end',\n",
    "                        'ensembl', 'mut_chr', 'mut_start', 'mut_end', 'mut_ref', 'mut_alt',\n",
    "                        'mut_sample', 'mut_type', 'mut_ID', 'overlap_bp'],  sep=\"\\s+\", index_col=False)\n",
    "    mutations_in_range2 = mutations_in_range2[mutations_in_range2['overlap_bp'] != 0]\n",
    "    mutations_in_range2 = mutations_in_range2[['mut_chr', 'mut_start', 'mut_end', 'mut_ref', \n",
    "                        'mut_alt', 'mut_sample', 'mut_type', 'mut_ID']]\n",
    "    mutations_in_range2.columns = ['chr', 'start', 'end', 'ref', 'alt', 'sample', 'type', 'ID']\n",
    "    \n",
    "    \n",
    "    mutations_in_range2['category'] = mutations_in_range2.apply(lambda x: \n",
    "                           check_consequence_TEST(x['chr'], x['end'], x['alt'], tb_consequence_type), axis=1)\n",
    "    all_elements = mutations_in_range2['category'].tolist()\n",
    "    unique_elements = set(all_elements)\n",
    "    for n in unique_elements:\n",
    "        count = countX(all_elements, n)\n",
    "        print (\"The category \" + str(n) + \" is found \" + str(count) + \" times.\")\n",
    "\n",
    "    # Find if mutations at exonic regions are synonymous or not.\n",
    "    mutations_in_range2['conseq'] = mutations_in_range2.apply(lambda x: \n",
    "                       check_consequence(x['chr'], x['end'], x['alt'], tb_consequence_type, consequence_rank_dict),\n",
    "                       axis=1)\n",
    "    \n",
    "    # Drop exonic outsise 2001-nt window\n",
    "    muts_to_drop = mutations_in_range2[mutations_in_range2['conseq'] != include]\n",
    "    IDs_to_drop = muts_to_drop['ID'].tolist()\n",
    "    mutations_in_range = remove_muts(mutations_in_range, IDs_to_drop)\n",
    "    \n",
    "    # Drop recurrent mutations\n",
    "    mutations_in_range = mutations_in_range[['mut_chr', 'mut_start', 'mut_end', 'mut_ref',\n",
    "                                             'mut_alt']].drop_duplicates()\n",
    "    mutations_in_range.columns = ['chr', 'start', 'end', 'ref', 'alt']\n",
    "    \n",
    "    # Compute dictionary of mutations\n",
    "    mutations_in_range['ref_kmer'] = mutations_in_range.apply(lambda x: hg19(x['chr'],\n",
    "                                                                            x['start']+1-(k//2),1+2*(k//2)), axis=1)\n",
    "    mutations_in_range['alt_kmer'] = mutations_in_range.apply(lambda x: compute_kmer_alt(x, k), axis=1)\n",
    "    mutations_in_range['mutation'] = list(zip(mutations_in_range.ref_kmer, mutations_in_range.alt_kmer))\n",
    "    mutations_in_range['coords'] = list(zip(mutations_in_range.chr, mutations_in_range.start))\n",
    "    mut_dict = mutations_in_range.set_index('coords')['mutation'].T.to_dict()\n",
    "    \n",
    "    log_ll = 0\n",
    "    \n",
    "    # For each exon, each row, each 2001-nt sequence\n",
    "    for my_row in region_coords.values.tolist():\n",
    "\n",
    "        ## Get coordinates\n",
    "        my_chr = my_row[0]\n",
    "        my_start = int(my_row[1])\n",
    "        my_end = int(my_row[2])\n",
    "        n_bases = my_end - my_start\n",
    "        \n",
    "        ## Get sequence.\n",
    "        my_exon_bases = hg19(my_chr, my_start+1-(k//2), size=n_bases+2*(k//2))\n",
    "        ## Divide sequences into kmers\n",
    "        my_kmers = [my_exon_bases[i:i+k] for i in range(len(my_exon_bases)-(k-1))]\n",
    "\n",
    "        for i in range(0,len(my_kmers)):\n",
    "            pos = my_start + i\n",
    "            try:\n",
    "                log_ll = log_ll + np.log(prob_dict[str(mut_dict[(my_chr, pos)])])\n",
    "            except:\n",
    "                log_ll = log_ll + np.log(prob_dict[str(tuple((my_kmers[i],my_kmers[i])))])\n",
    "\n",
    "    return(log_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_likelihood_excluding_CpG(k, mutation_df, exon_coords, signatures_file, middle_distance_threshold, include):\n",
    "    \n",
    "    nucleotides = set(['A', 'T', 'C', 'G'])\n",
    "    \n",
    "    middle_exon_coords = exon_coords.copy(deep=True)\n",
    "    \n",
    "    # Process signatures\n",
    "    all_signatures = pd.read_csv(signatures_file, sep='\\t')\n",
    "    name = 'Probability_germinal'\n",
    "    sub_signatures_df = all_signatures[['mutation', name]]\n",
    "    prob_dict = sub_signatures_df.set_index('mutation')[name].T.to_dict()\n",
    "    \n",
    "    # Add probability of no mutation (manually)\n",
    "    prob_dict[str(('A','A'))] = 1 - prob_dict[str(('A','C'))] - prob_dict[str(('A','G'))] - prob_dict[str(('A','T'))]\n",
    "    prob_dict[str(('T','T'))] = 1 - prob_dict[str(('T','C'))] - prob_dict[str(('T','G'))] - prob_dict[str(('T','A'))]\n",
    "    prob_dict[str(('CpG','CpG'))] = 1 - prob_dict[str(('CpG','T'))] - prob_dict[str(('CpG','G'))] - prob_dict[str(('CpG','A'))]\n",
    "    prob_dict[str(('GpC','GpC'))] = 1 - prob_dict[str(('GpC','A'))] - prob_dict[str(('GpC','C'))] - prob_dict[str(('GpC','T'))]\n",
    "    prob_dict[str(('nonCpG','nonCpG'))] = 1 - prob_dict[str(('nonCpG','T'))] - prob_dict[str(('nonCpG','G'))] - prob_dict[str(('nonCpG','A'))]\n",
    "    prob_dict[str(('nonGpC','nonGpC'))] = 1 - prob_dict[str(('nonGpC','A'))] - prob_dict[str(('nonGpC','C'))] - prob_dict[str(('nonGpC','T'))]\n",
    "    \n",
    "    # Convert exonic coordinates into bed to intersect values\n",
    "    exon_coords_bed = pybedtools.BedTool.from_dataframe(middle_exon_coords)\n",
    "    \n",
    "    # Process coordinates\n",
    "    middle_exon_coords['exon_size'] = (middle_exon_coords['end'] - middle_exon_coords['start'])\n",
    "    middle_exon_coords['exon_middle_start'] = (middle_exon_coords['start'] + middle_exon_coords['exon_size']/2)\n",
    "    middle_exon_coords['exon_middle_start'] = middle_exon_coords.apply(lambda x:\n",
    "                                                                    math.floor(x['exon_middle_start']),\n",
    "                                                                    axis=1)\n",
    "    \n",
    "    middle_exon_coords['exon_middle_end'] = middle_exon_coords['exon_middle_start'] + 1\n",
    "    middle_exon_coords['region_start'] = middle_exon_coords['exon_middle_start'] - middle_distance_threshold\n",
    "    middle_exon_coords['region_end'] = middle_exon_coords['exon_middle_end'] + middle_distance_threshold\n",
    "    region_coords = middle_exon_coords[['chr', 'region_start', 'region_end', 'ensembl', 'exon_size', 'start', 'end']]\n",
    "    region_coords_bed = pybedtools.BedTool.from_dataframe(region_coords)\n",
    "    \n",
    "    # Process mutations\n",
    "    mutations_bed = pybedtools.BedTool.from_dataframe(mutation_df)\n",
    "    my_bed = region_coords_bed.intersect(mutations_bed, wao=True)\n",
    "    \n",
    "    # Filter mutations by the full region of interest\n",
    "    mutations_in_range = pd.read_table(my_bed.fn, names = ['chr', 'region_start', 'region_end',\n",
    "                        'ensembl', 'exon_size', 'exon_start', 'exon_end', 'mut_chr', 'mut_start', 'mut_end', 'mut_ref', 'mut_alt',\n",
    "                        'mut_sample', 'mut_type', 'mut_ID', 'overlap_bp'],  sep=\"\\s+\", index_col=False)\n",
    "    mutations_in_range = mutations_in_range[mutations_in_range['overlap_bp'] != 0]\n",
    "    \n",
    "    \n",
    "    # Filter mutations by the exonic regions\n",
    "    my_bed2 = exon_coords_bed.intersect(mutations_bed, wao=True)\n",
    "    mutations_in_range2 = pd.read_table(my_bed2.fn, names = ['exon_chr', 'exon_start', 'exon_end',\n",
    "                        'ensembl', 'mut_chr', 'mut_start', 'mut_end', 'mut_ref', 'mut_alt',\n",
    "                        'mut_sample', 'mut_type', 'mut_ID', 'overlap_bp'],  sep=\"\\s+\", index_col=False)\n",
    "    mutations_in_range2 = mutations_in_range2[mutations_in_range2['overlap_bp'] != 0]\n",
    "    mutations_in_range2 = mutations_in_range2[['mut_chr', 'mut_start', 'mut_end', 'mut_ref', \n",
    "                        'mut_alt', 'mut_sample', 'mut_type', 'mut_ID']]\n",
    "    mutations_in_range2.columns = ['chr', 'start', 'end', 'ref', 'alt', 'sample', 'type', 'ID']\n",
    "    \n",
    "    \n",
    "    mutations_in_range2['category'] = mutations_in_range2.apply(lambda x: \n",
    "                           check_consequence_TEST(x['chr'], x['end'], x['alt'], tb_consequence_type), axis=1)\n",
    "    all_elements = mutations_in_range2['category'].tolist()\n",
    "    unique_elements = set(all_elements)\n",
    "    for n in unique_elements:\n",
    "        count = countX(all_elements, n)\n",
    "        print (\"The category \" + str(n) + \" is found \" + str(count) + \" times.\")\n",
    "\n",
    "    # Find if mutations at exonic regions are synonymous or not.\n",
    "    mutations_in_range2['conseq'] = mutations_in_range2.apply(lambda x: \n",
    "                       check_consequence(x['chr'], x['end'], x['alt'], tb_consequence_type, consequence_rank_dict),\n",
    "                       axis=1)\n",
    "    \n",
    "    # Drop exonic outsise 2001-nt window\n",
    "    muts_to_drop = mutations_in_range2[mutations_in_range2['conseq'] != include]\n",
    "    IDs_to_drop = muts_to_drop['ID'].tolist()\n",
    "    mutations_in_range = remove_muts(mutations_in_range, IDs_to_drop)\n",
    "    \n",
    "    # Drop recurrent mutations\n",
    "    mutations_in_range = mutations_in_range[['mut_chr', 'mut_start', 'mut_end', 'mut_ref',\n",
    "                                             'mut_alt']].drop_duplicates()\n",
    "    mutations_in_range.columns = ['chr', 'start', 'end', 'ref', 'alt']\n",
    "    \n",
    "    # Compute dictionary of mutations\n",
    "    mutations_in_range['ref_kmer'] = mutations_in_range.apply(lambda x: hg19(x['chr'],\n",
    "                                                                            x['start']+1-(k//2),1+2*(k//2)), axis=1)\n",
    "    mutations_in_range[['pre', 'nt', 'post']] = mutations_in_range['ref_kmer'].apply(lambda x: pd.Series(list(x)))\n",
    "    mutations_in_range['site'] = mutations_in_range.apply(lambda x: compute_CpG_site(x), axis=1)\n",
    "    mutations_in_range['mutation'] = list(zip(mutations_in_range.site, mutations_in_range.alt))\n",
    "    mutations_in_range['coords'] = list(zip(mutations_in_range.chr, mutations_in_range.start))\n",
    "    mut_dict = mutations_in_range.set_index('coords')['mutation'].T.to_dict()\n",
    "    \n",
    "    log_ll = 0\n",
    "    \n",
    "    # For each exon, each row, each 2001-nt sequence\n",
    "    for my_row in region_coords.values.tolist():\n",
    "\n",
    "        ## Get coordinates\n",
    "        my_chr = my_row[0]\n",
    "        my_start = int(my_row[1])\n",
    "        my_end = int(my_row[2])\n",
    "        n_bases = my_end - my_start\n",
    "        \n",
    "        ## Get sequence.\n",
    "        my_exon_bases = hg19(my_chr, my_start+1-(k//2), size=n_bases+2*(k//2))\n",
    "        ## Divide sequences into kmers\n",
    "        my_kmers = [my_exon_bases[i:i+k] for i in range(len(my_exon_bases)-(k-1))]\n",
    "\n",
    "        for i in range(0,len(my_kmers)):\n",
    "            pos = my_start + i\n",
    "            site = compute_CpG_site_string(my_kmers[i])\n",
    "            try:\n",
    "                log_ll = log_ll + np.log(prob_dict[str(mut_dict[(my_chr, pos)])])\n",
    "            except:\n",
    "                log_ll = log_ll + np.log(prob_dict[str((site,site))])\n",
    "\n",
    "    return(log_ll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Goldmann 2018: Compute log likelihood for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get the mutations\n",
    "mutations_file = 'non_provided_data/mutations/germinal_ultimate_dataset.bed.gz'\n",
    "mutations_df = pd.read_csv(mutations_file, sep=\"\\t\", header=None)\n",
    "mutations_df.columns = ['chr', 'start', 'end', 'ref', 'alt', 'sample', 'type', 'class']\n",
    "mutations_df = mutations_df[['chr', 'start', 'end', 'ref', 'alt', 'sample', 'type']]\n",
    "mutations_df = mutations_df[mutations_df['type'] == 'subs']\n",
    "mutations_df = mutations_df[mutations_df['sample'] == 'Goldmann2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "middle_exons_file = 'data/coordinates/genes_middle_exon_coords.bed.gz'\n",
    "\n",
    "## Get exon coordinates\n",
    "exons_coords_df = pd.read_csv(middle_exons_file, sep=\"\\t\", header=None, low_memory=False)\n",
    "exons_coords_df.columns = ['chr', 'start', 'end', 'ensembl', 'symbol', 'strand']\n",
    "exons_coords_df = exons_coords_df[['chr', 'start', 'end', 'ensembl']]\n",
    "exons_coords_df['ensembl'] = exons_coords_df.apply(lambda x: remove_version_ensembl(x, 'ensembl'), axis=1)\n",
    "exons_coords_df.columns = ['chr', 'start', 'end', 'ensembl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_dict = {'model': [], 'log_likelihood': [], 'n_param': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 1\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_signatures_DNM_golden.txt'\n",
    "\n",
    "result = log_likelihood(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(4**k*3)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-mer with CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/CpG_signatures_DNM_golden.txt'\n",
    "\n",
    "result = log_likelihood_CpG(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold)\n",
    "results_dict['model'].append('CpG')\n",
    "results_dict['n_param'].append(18)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_signatures_DNM_golden.txt'\n",
    "\n",
    "result = log_likelihood(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(4**k*3)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "h = 3\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_DNM_decomp_golden.txt'\n",
    "\n",
    "result = log_likelihood(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(((4**h*3)*((k-h)*3)) # Linear increase form the core exponential increase\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 7\n",
    "h = 3\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_DNM_decomp_golden.txt'\n",
    "\n",
    "result = log_likelihood(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(((4**h)*3)*((k-h)*3)) # Linear increase form the core exponential increase\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_dict, columns=['model', 'log_likelihood', 'n_param'])\n",
    "filename = 'model_golden.txt'\n",
    "\n",
    "results_df.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load model information\n",
    "models_file = 'results/model_golden.txt'\n",
    "models_df = pd.read_csv(models_file, sep=\"\\t\", header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute AIC\n",
    "models_df['AIC'] = models_df.apply(lambda x: compute_AIC(x['log_likelihood'], x['n_param']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_df[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## All DNM: Compute log likelihood for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get the mutations\n",
    "mutations_file = 'non_provided_data/mutations/germinal_ultimate_dataset.bed.gz'\n",
    "mutations_df = pd.read_csv(mutations_file, sep=\"\\t\", header=None)\n",
    "mutations_df.columns = ['chr', 'start', 'end', 'ref', 'alt', 'sample', 'type', 'class']\n",
    "mutations_df = mutations_df[['chr', 'start', 'end', 'ref', 'alt', 'sample', 'type']]\n",
    "mutations_df = mutations_df[mutations_df['type'] == 'subs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "middle_exons_file = 'data/coordinates/genes_middle_exon_coords.bed.gz'\n",
    "\n",
    "## Get exon coordinates\n",
    "exons_coords_df = pd.read_csv(middle_exons_file, sep=\"\\t\", header=None, low_memory=False)\n",
    "exons_coords_df.columns = ['chr', 'start', 'end', 'ensembl', 'symbol', 'strand']\n",
    "exons_coords_df = exons_coords_df[['chr', 'start', 'end', 'ensembl']]\n",
    "exons_coords_df['ensembl'] = exons_coords_df.apply(lambda x: remove_version_ensembl(x, 'ensembl'), axis=1)\n",
    "exons_coords_df.columns = ['chr', 'start', 'end', 'ensembl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_dict = {'model': [], 'log_likelihood': [], 'n_param': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 1\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_signatures_DNM.txt'\n",
    "\n",
    "result = log_likelihood(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(4**k*3)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-mer with CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/CpG_signatures_DNM.txt'\n",
    "\n",
    "result = log_likelihood_CpG(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold)\n",
    "results_dict['model'].append('CpG')\n",
    "results_dict['n_param'].append(18)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_signatures_DNM.txt'\n",
    "\n",
    "result = log_likelihood(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(4**k*3)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_signatures_DNM.txt'\n",
    "\n",
    "result = log_likelihood(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(4**k*3)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 7\n",
    "h = 5\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_DNM_decomp.txt'\n",
    "\n",
    "result = log_likelihood(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(((4**h)*3)*((k-h)*3)) # Linear increase form the core exponential increase\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_dict, columns=['model', 'log_likelihood', 'n_param'])\n",
    "filename = 'model_all_k7h5.txt'\n",
    "\n",
    "results_df.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load model information\n",
    "models_file = 'results/model_all_k7h5.txt'\n",
    "models_df = pd.read_csv(models_file, sep=\"\\t\", header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute AIC\n",
    "models_df['AIC'] = models_df.apply(lambda x: compute_AIC(x['log_likelihood'], x['n_param']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Goldmann, synonymous vs non-synonymous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get the mutations\n",
    "mutations_file = 'non_provided_data/mutations/germinal_ultimate_dataset.bed.gz'\n",
    "mutations_df = pd.read_csv(mutations_file, sep=\"\\t\", header=None)\n",
    "mutations_df.columns = ['chr', 'start', 'end', 'ref', 'alt', 'sample', 'type', 'class']\n",
    "mutations_df = mutations_df[['chr', 'start', 'end', 'ref', 'alt', 'sample', 'type']]\n",
    "mutations_df = mutations_df[mutations_df['type'] == 'subs']\n",
    "mutations_df = mutations_df[mutations_df['sample'] == 'Goldmann2018']\n",
    "mutations_df['ID'] = mutations_df.index + 1\n",
    "\n",
    "consequence_type_file = 'data/consequence/consequence_ranking.tsv.bgz'\n",
    "consequence_ranking_file = 'data/consequence/consequence_ranking_info.tsv'\n",
    "\n",
    "## Get consequence tabix file\n",
    "tb_consequence_type = tabix.open(consequence_type_file)\n",
    "\n",
    "## Get the consequence rank info and classify separate syn from other types of non-syn (missense, non-sense,...)\n",
    "consequence_rank_info = pd.read_csv(consequence_ranking_file, delimiter='\\t')\n",
    "consequence_rank_info['TYPE'] = consequence_rank_info.apply(lambda x:synonymous_or_not(x) ,1)\n",
    "consequence_rank_info = consequence_rank_info[['CONSEQUENCE', 'TYPE']]\n",
    "consequence_rank_dict = dict(zip(consequence_rank_info['CONSEQUENCE'], consequence_rank_info['TYPE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "middle_exons_file = 'data/coordinates/genes_middle_exon_coords.bed.gz'\n",
    "\n",
    "## Get exon coordinates\n",
    "exons_coords_df = pd.read_csv(middle_exons_file, sep=\"\\t\", header=None, low_memory=False)\n",
    "exons_coords_df.columns = ['chr', 'start', 'end', 'ensembl', 'symbol', 'strand']\n",
    "exons_coords_df = exons_coords_df[['chr', 'start', 'end', 'ensembl']]\n",
    "exons_coords_df['ensembl'] = exons_coords_df.apply(lambda x: remove_version_ensembl(x, 'ensembl'), axis=1)\n",
    "exons_coords_df.columns = ['chr', 'start', 'end', 'ensembl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_dict = {'model': [], 'log_likelihood': [], 'n_param': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SYNONYMOUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "include = 'synonymous'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category splice_region_variant is found 2 times.\n",
      "The category synonymous_variant is found 130 times.\n",
      "The category initiator_codon_variant is found 1 times.\n",
      "The category missense_variant is found 336 times.\n",
      "The category stop_gained is found 25 times.\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_signatures_DNM_golden.txt'\n",
    "\n",
    "result = log_likelihood_excluding(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold, include)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(4**k*3)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-mer with CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category splice_region_variant is found 2 times.\n",
      "The category synonymous_variant is found 130 times.\n",
      "The category initiator_codon_variant is found 1 times.\n",
      "The category missense_variant is found 336 times.\n",
      "The category stop_gained is found 25 times.\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/CpG_signatures_DNM_golden.txt'\n",
    "\n",
    "result = log_likelihood_excluding_CpG(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold, include)\n",
    "results_dict['model'].append('CpG')\n",
    "results_dict['n_param'].append(18)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category splice_region_variant is found 2 times.\n",
      "The category synonymous_variant is found 130 times.\n",
      "The category initiator_codon_variant is found 1 times.\n",
      "The category missense_variant is found 336 times.\n",
      "The category stop_gained is found 25 times.\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_signatures_DNM_golden.txt'\n",
    "\n",
    "result = log_likelihood_excluding(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold, include)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(4**k*3)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category splice_region_variant is found 2 times.\n",
      "The category synonymous_variant is found 130 times.\n",
      "The category initiator_codon_variant is found 1 times.\n",
      "The category missense_variant is found 336 times.\n",
      "The category stop_gained is found 25 times.\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "h = 3\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_DNM_decomp_golden.txt'\n",
    "\n",
    "result = log_likelihood_excluding(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold, include)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(((4**h)*3)*((k-h)*3)) # Linear increase form the core exponential increase\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category splice_region_variant is found 2 times.\n",
      "The category synonymous_variant is found 130 times.\n",
      "The category initiator_codon_variant is found 1 times.\n",
      "The category missense_variant is found 336 times.\n",
      "The category stop_gained is found 25 times.\n"
     ]
    }
   ],
   "source": [
    "k = 7\n",
    "h = 5\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_DNM_decomp_golden.txt'\n",
    "\n",
    "result = log_likelihood_excluding(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold, include)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(((4**h)*3)*((k-h)*3)) # Linear increase form the core exponential increase\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_dict, columns=['model', 'log_likelihood', 'n_param'])\n",
    "filename = 'model_golden_syn.txt'\n",
    "\n",
    "results_df.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load model information\n",
    "models_file = 'results/model_golden_syn.txt'\n",
    "models_df = pd.read_csv(models_file, sep=\"\\t\", header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute AIC\n",
    "models_df['AIC'] = models_df.apply(lambda x: compute_AIC(x['log_likelihood'], x['n_param']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>log_likelihood</th>\n",
       "      <th>n_param</th>\n",
       "      <th>AIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1mer</td>\n",
       "      <td>-65704.130856</td>\n",
       "      <td>12</td>\n",
       "      <td>131432.261713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CpG</td>\n",
       "      <td>-64306.218850</td>\n",
       "      <td>18</td>\n",
       "      <td>128648.437699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3mer</td>\n",
       "      <td>-64036.529684</td>\n",
       "      <td>192</td>\n",
       "      <td>128457.059368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5mer</td>\n",
       "      <td>-63795.550749</td>\n",
       "      <td>3072</td>\n",
       "      <td>133735.101498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7mer</td>\n",
       "      <td>-63725.577705</td>\n",
       "      <td>49152</td>\n",
       "      <td>225755.155409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  log_likelihood  n_param            AIC\n",
       "0  1mer   -65704.130856       12  131432.261713\n",
       "1   CpG   -64306.218850       18  128648.437699\n",
       "2  3mer   -64036.529684      192  128457.059368\n",
       "3  5mer   -63795.550749     3072  133735.101498\n",
       "4  7mer   -63725.577705    49152  225755.155409"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NON_SYNONYMOUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "include = 'non_synonymous'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category splice_region_variant is found 2 times.\n",
      "The category synonymous_variant is found 130 times.\n",
      "The category initiator_codon_variant is found 1 times.\n",
      "The category missense_variant is found 336 times.\n",
      "The category stop_gained is found 25 times.\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_signatures_DNM_golden.txt'\n",
    "\n",
    "result = log_likelihood_excluding(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold, include)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(4**k*3)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-mer with CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category splice_region_variant is found 2 times.\n",
      "The category synonymous_variant is found 130 times.\n",
      "The category initiator_codon_variant is found 1 times.\n",
      "The category missense_variant is found 336 times.\n",
      "The category stop_gained is found 25 times.\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/CpG_signatures_DNM_golden.txt'\n",
    "\n",
    "result = log_likelihood_excluding_CpG(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold, include)\n",
    "results_dict['model'].append('CpG')\n",
    "results_dict['n_param'].append(18)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category splice_region_variant is found 2 times.\n",
      "The category synonymous_variant is found 130 times.\n",
      "The category initiator_codon_variant is found 1 times.\n",
      "The category missense_variant is found 336 times.\n",
      "The category stop_gained is found 25 times.\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_signatures_DNM_golden.txt'\n",
    "\n",
    "result = log_likelihood_excluding(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold, include)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(4**k*3)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category splice_region_variant is found 2 times.\n",
      "The category synonymous_variant is found 130 times.\n",
      "The category initiator_codon_variant is found 1 times.\n",
      "The category missense_variant is found 336 times.\n",
      "The category stop_gained is found 25 times.\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "h = 3\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_DNM_decomp_golden.txt'\n",
    "\n",
    "result = log_likelihood_excluding(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold, include)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(((4**h)*3)*((k-h)*3)) # Linear increase form the core exponential increase\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category splice_region_variant is found 2 times.\n",
      "The category synonymous_variant is found 130 times.\n",
      "The category initiator_codon_variant is found 1 times.\n",
      "The category missense_variant is found 336 times.\n",
      "The category stop_gained is found 25 times.\n"
     ]
    }
   ],
   "source": [
    "k = 7\n",
    "h = 3\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_DNM_decomp_golden.txt'\n",
    "\n",
    "result = log_likelihood_excluding(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold, include)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(((4**h)*3)*((k-h)*3)) # Linear increase form the core exponential increase\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_dict, columns=['model', 'log_likelihood', 'n_param'])\n",
    "filename = 'model_golden_nonsyn.txt'\n",
    "\n",
    "results_df.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load model information\n",
    "models_file = 'results/model_golden_nonsyn.txt'\n",
    "models_df = pd.read_csv(models_file, sep=\"\\t\", header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute AIC\n",
    "models_df['AIC'] = models_df.apply(lambda x: compute_AIC(x['log_likelihood'], x['n_param']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>log_likelihood</th>\n",
       "      <th>n_param</th>\n",
       "      <th>AIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1mer</td>\n",
       "      <td>-65704.130856</td>\n",
       "      <td>12</td>\n",
       "      <td>131432.261713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CpG</td>\n",
       "      <td>-64306.218850</td>\n",
       "      <td>18</td>\n",
       "      <td>128648.437699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3mer</td>\n",
       "      <td>-64036.529684</td>\n",
       "      <td>192</td>\n",
       "      <td>128457.059368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5mer</td>\n",
       "      <td>-63795.550749</td>\n",
       "      <td>3072</td>\n",
       "      <td>133735.101498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7mer</td>\n",
       "      <td>-63725.577705</td>\n",
       "      <td>49152</td>\n",
       "      <td>225755.155409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1mer</td>\n",
       "      <td>-67336.345083</td>\n",
       "      <td>12</td>\n",
       "      <td>134696.690167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CpG</td>\n",
       "      <td>-65870.714371</td>\n",
       "      <td>18</td>\n",
       "      <td>131777.428742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3mer</td>\n",
       "      <td>-65592.225899</td>\n",
       "      <td>192</td>\n",
       "      <td>131568.451797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5mer</td>\n",
       "      <td>-65332.703955</td>\n",
       "      <td>3072</td>\n",
       "      <td>136809.407910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7mer</td>\n",
       "      <td>-65256.830314</td>\n",
       "      <td>49152</td>\n",
       "      <td>228817.660627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  log_likelihood  n_param            AIC\n",
       "0  1mer   -65704.130856       12  131432.261713\n",
       "1   CpG   -64306.218850       18  128648.437699\n",
       "2  3mer   -64036.529684      192  128457.059368\n",
       "3  5mer   -63795.550749     3072  133735.101498\n",
       "4  7mer   -63725.577705    49152  225755.155409\n",
       "5  1mer   -67336.345083       12  134696.690167\n",
       "6   CpG   -65870.714371       18  131777.428742\n",
       "7  3mer   -65592.225899      192  131568.451797\n",
       "8  5mer   -65332.703955     3072  136809.407910\n",
       "9  7mer   -65256.830314    49152  228817.660627"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All datasets, synonymous vs non-synonymous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get the mutations\n",
    "mutations_file = 'non_provided_data/mutations/germinal_ultimate_dataset.bed.gz'\n",
    "mutations_df = pd.read_csv(mutations_file, sep=\"\\t\", header=None)\n",
    "mutations_df.columns = ['chr', 'start', 'end', 'ref', 'alt', 'sample', 'type', 'class']\n",
    "mutations_df = mutations_df[['chr', 'start', 'end', 'ref', 'alt', 'sample', 'type']]\n",
    "mutations_df = mutations_df[mutations_df['type'] == 'subs']\n",
    "mutations_df['ID'] = mutations_df.index + 1\n",
    "\n",
    "consequence_type_file = 'data/consequence/consequence_ranking.tsv.bgz'\n",
    "consequence_ranking_file = 'data/consequence/consequence_ranking_info.tsv'\n",
    "\n",
    "## Get consequence tabix file\n",
    "tb_consequence_type = tabix.open(consequence_type_file)\n",
    "\n",
    "## Get the consequence rank info and classify separate syn from other types of non-syn (missense, non-sense,...)\n",
    "consequence_rank_info = pd.read_csv(consequence_ranking_file, delimiter='\\t')\n",
    "consequence_rank_info['TYPE'] = consequence_rank_info.apply(lambda x:synonymous_or_not(x) ,1)\n",
    "consequence_rank_info = consequence_rank_info[['CONSEQUENCE', 'TYPE']]\n",
    "consequence_rank_dict = dict(zip(consequence_rank_info['CONSEQUENCE'], consequence_rank_info['TYPE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "middle_exons_file = 'data/coordinates/genes_middle_exon_coords.bed.gz'\n",
    "\n",
    "## Get exon coordinates\n",
    "exons_coords_df = pd.read_csv(middle_exons_file, sep=\"\\t\", header=None, low_memory=False)\n",
    "exons_coords_df.columns = ['chr', 'start', 'end', 'ensembl', 'symbol', 'strand']\n",
    "exons_coords_df = exons_coords_df[['chr', 'start', 'end', 'ensembl']]\n",
    "exons_coords_df['ensembl'] = exons_coords_df.apply(lambda x: remove_version_ensembl(x, 'ensembl'), axis=1)\n",
    "exons_coords_df.columns = ['chr', 'start', 'end', 'ensembl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_dict = {'model': [], 'log_likelihood': [], 'n_param': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SYNONYMOUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "include = 'synonymous'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category splice_region_variant is found 58 times.\n",
      "The category None is found 10 times.\n",
      "The category 5 is found 2 times.\n",
      "The category synonymous_variant is found 1184 times.\n",
      "The category downstream_gene_variant is found 2 times.\n",
      "The category initiator_codon_variant is found 6 times.\n",
      "The category splice_acceptor_variant is found 1 times.\n",
      "The category missense_variant is found 3280 times.\n",
      "The category upstream_gene_variant is found 8 times.\n",
      "The category stop_gained is found 202 times.\n",
      "The category intron_variant is found 1 times.\n",
      "The category splice_donor_variant is found 3 times.\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_signatures_DNM.txt'\n",
    "\n",
    "result = log_likelihood_excluding(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold, include)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(4**k*3)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-mer with CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category splice_region_variant is found 58 times.\n",
      "The category None is found 10 times.\n",
      "The category 5 is found 2 times.\n",
      "The category synonymous_variant is found 1184 times.\n",
      "The category downstream_gene_variant is found 2 times.\n",
      "The category initiator_codon_variant is found 6 times.\n",
      "The category splice_acceptor_variant is found 1 times.\n",
      "The category missense_variant is found 3280 times.\n",
      "The category upstream_gene_variant is found 8 times.\n",
      "The category stop_gained is found 202 times.\n",
      "The category intron_variant is found 1 times.\n",
      "The category splice_donor_variant is found 3 times.\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/CpG_signatures_DNM.txt'\n",
    "\n",
    "result = log_likelihood_excluding_CpG(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold, include)\n",
    "results_dict['model'].append('CpG')\n",
    "results_dict['n_param'].append(18)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category splice_region_variant is found 58 times.\n",
      "The category None is found 10 times.\n",
      "The category 5 is found 2 times.\n",
      "The category synonymous_variant is found 1184 times.\n",
      "The category downstream_gene_variant is found 2 times.\n",
      "The category initiator_codon_variant is found 6 times.\n",
      "The category splice_acceptor_variant is found 1 times.\n",
      "The category missense_variant is found 3280 times.\n",
      "The category upstream_gene_variant is found 8 times.\n",
      "The category stop_gained is found 202 times.\n",
      "The category intron_variant is found 1 times.\n",
      "The category splice_donor_variant is found 3 times.\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_signatures_DNM.txt'\n",
    "\n",
    "result = log_likelihood_excluding(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold, include)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(4**k*3)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category splice_region_variant is found 58 times.\n",
      "The category None is found 10 times.\n",
      "The category 5 is found 2 times.\n",
      "The category synonymous_variant is found 1184 times.\n",
      "The category downstream_gene_variant is found 2 times.\n",
      "The category initiator_codon_variant is found 6 times.\n",
      "The category splice_acceptor_variant is found 1 times.\n",
      "The category missense_variant is found 3280 times.\n",
      "The category upstream_gene_variant is found 8 times.\n",
      "The category stop_gained is found 202 times.\n",
      "The category intron_variant is found 1 times.\n",
      "The category splice_donor_variant is found 3 times.\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_signatures_DNM.txt'\n",
    "\n",
    "result = log_likelihood_excluding(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold, include)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(4**k*3)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category splice_region_variant is found 58 times.\n",
      "The category None is found 10 times.\n",
      "The category 5 is found 2 times.\n",
      "The category synonymous_variant is found 1184 times.\n",
      "The category downstream_gene_variant is found 2 times.\n",
      "The category initiator_codon_variant is found 6 times.\n",
      "The category splice_acceptor_variant is found 1 times.\n",
      "The category missense_variant is found 3280 times.\n",
      "The category upstream_gene_variant is found 8 times.\n",
      "The category stop_gained is found 202 times.\n",
      "The category intron_variant is found 1 times.\n",
      "The category splice_donor_variant is found 3 times.\n"
     ]
    }
   ],
   "source": [
    "k = 7\n",
    "h = 5\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_DNM_decomp.txt'\n",
    "\n",
    "result = log_likelihood_excluding(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold, include)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(((4**h)*3)*((k-h)*3)) # Linear increase form the core exponential increase\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_dict, columns=['model', 'log_likelihood', 'n_param'])\n",
    "filename = 'model_syn.txt'\n",
    "\n",
    "results_df.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load model information\n",
    "models_file = 'results/model_syn.txt'\n",
    "models_df = pd.read_csv(models_file, sep=\"\\t\", header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute AIC\n",
    "models_df['AIC'] = models_df.apply(lambda x: compute_AIC(x['log_likelihood'], x['n_param']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>log_likelihood</th>\n",
       "      <th>n_param</th>\n",
       "      <th>AIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1mer</td>\n",
       "      <td>-483499.622290</td>\n",
       "      <td>12</td>\n",
       "      <td>9.670232e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CpG</td>\n",
       "      <td>-468484.357064</td>\n",
       "      <td>18</td>\n",
       "      <td>9.370047e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3mer</td>\n",
       "      <td>-466394.156015</td>\n",
       "      <td>192</td>\n",
       "      <td>9.331723e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5mer</td>\n",
       "      <td>-464468.425375</td>\n",
       "      <td>3072</td>\n",
       "      <td>9.350809e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7mer</td>\n",
       "      <td>-462878.934210</td>\n",
       "      <td>49152</td>\n",
       "      <td>1.024062e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  log_likelihood  n_param           AIC\n",
       "0  1mer  -483499.622290       12  9.670232e+05\n",
       "1   CpG  -468484.357064       18  9.370047e+05\n",
       "2  3mer  -466394.156015      192  9.331723e+05\n",
       "3  5mer  -464468.425375     3072  9.350809e+05\n",
       "4  7mer  -462878.934210    49152  1.024062e+06"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NON_SYNONYMOUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "include = 'non_synonymous'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category splice_region_variant is found 58 times.\n",
      "The category None is found 10 times.\n",
      "The category 5 is found 2 times.\n",
      "The category synonymous_variant is found 1184 times.\n",
      "The category downstream_gene_variant is found 2 times.\n",
      "The category initiator_codon_variant is found 6 times.\n",
      "The category splice_acceptor_variant is found 1 times.\n",
      "The category missense_variant is found 3280 times.\n",
      "The category upstream_gene_variant is found 8 times.\n",
      "The category stop_gained is found 202 times.\n",
      "The category intron_variant is found 1 times.\n",
      "The category splice_donor_variant is found 3 times.\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_signatures_DNM.txt'\n",
    "\n",
    "result = log_likelihood_excluding(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold, include)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(4**k*3)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-mer with CpG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category splice_region_variant is found 58 times.\n",
      "The category None is found 10 times.\n",
      "The category 5 is found 2 times.\n",
      "The category synonymous_variant is found 1184 times.\n",
      "The category downstream_gene_variant is found 2 times.\n",
      "The category initiator_codon_variant is found 6 times.\n",
      "The category splice_acceptor_variant is found 1 times.\n",
      "The category missense_variant is found 3280 times.\n",
      "The category upstream_gene_variant is found 8 times.\n",
      "The category stop_gained is found 202 times.\n",
      "The category intron_variant is found 1 times.\n",
      "The category splice_donor_variant is found 3 times.\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/CpG_signatures_DNM.txt'\n",
    "\n",
    "result = log_likelihood_excluding_CpG(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold, include)\n",
    "results_dict['model'].append('CpG')\n",
    "results_dict['n_param'].append(18)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category splice_region_variant is found 58 times.\n",
      "The category None is found 10 times.\n",
      "The category 5 is found 2 times.\n",
      "The category synonymous_variant is found 1184 times.\n",
      "The category downstream_gene_variant is found 2 times.\n",
      "The category initiator_codon_variant is found 6 times.\n",
      "The category splice_acceptor_variant is found 1 times.\n",
      "The category missense_variant is found 3280 times.\n",
      "The category upstream_gene_variant is found 8 times.\n",
      "The category stop_gained is found 202 times.\n",
      "The category intron_variant is found 1 times.\n",
      "The category splice_donor_variant is found 3 times.\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_signatures_DNM.txt'\n",
    "\n",
    "result = log_likelihood_excluding(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold, include)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(4**k*3)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category splice_region_variant is found 58 times.\n",
      "The category None is found 10 times.\n",
      "The category 5 is found 2 times.\n",
      "The category synonymous_variant is found 1184 times.\n",
      "The category downstream_gene_variant is found 2 times.\n",
      "The category initiator_codon_variant is found 6 times.\n",
      "The category splice_acceptor_variant is found 1 times.\n",
      "The category missense_variant is found 3280 times.\n",
      "The category upstream_gene_variant is found 8 times.\n",
      "The category stop_gained is found 202 times.\n",
      "The category intron_variant is found 1 times.\n",
      "The category splice_donor_variant is found 3 times.\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_signatures_DNM.txt'\n",
    "\n",
    "result = log_likelihood_excluding(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold, include)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(4**k*3)\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-mer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category splice_region_variant is found 58 times.\n",
      "The category None is found 10 times.\n",
      "The category 5 is found 2 times.\n",
      "The category synonymous_variant is found 1184 times.\n",
      "The category downstream_gene_variant is found 2 times.\n",
      "The category initiator_codon_variant is found 6 times.\n",
      "The category splice_acceptor_variant is found 1 times.\n",
      "The category missense_variant is found 3280 times.\n",
      "The category upstream_gene_variant is found 8 times.\n",
      "The category stop_gained is found 202 times.\n",
      "The category intron_variant is found 1 times.\n",
      "The category splice_donor_variant is found 3 times.\n"
     ]
    }
   ],
   "source": [
    "k = 7\n",
    "h = 5\n",
    "middle_distance_threshold = 1000\n",
    "\n",
    "signatures_file = 'results/' + str(k) + 'mer_DNM_decomp.txt'\n",
    "\n",
    "result = log_likelihood_excluding(k, mutations_df, exons_coords_df, signatures_file, middle_distance_threshold, include)\n",
    "results_dict['model'].append(str(k) + 'mer')\n",
    "results_dict['n_param'].append(((4**h)*3)*((k-h)*3)) # Linear increase form the core exponential increase\n",
    "results_dict['log_likelihood'].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_dict, columns=['model', 'log_likelihood', 'n_param'])\n",
    "filename = 'model_nonsyn.txt'\n",
    "\n",
    "results_df.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load model information\n",
    "models_file = 'results/model_nonsyn.txt'\n",
    "models_df = pd.read_csv(models_file, sep=\"\\t\", header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute AIC\n",
    "models_df['AIC'] = models_df.apply(lambda x: compute_AIC(x['log_likelihood'], x['n_param']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>log_likelihood</th>\n",
       "      <th>n_param</th>\n",
       "      <th>AIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1mer</td>\n",
       "      <td>-483499.622290</td>\n",
       "      <td>12</td>\n",
       "      <td>9.670232e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CpG</td>\n",
       "      <td>-468484.357064</td>\n",
       "      <td>18</td>\n",
       "      <td>9.370047e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3mer</td>\n",
       "      <td>-466394.156015</td>\n",
       "      <td>192</td>\n",
       "      <td>9.331723e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5mer</td>\n",
       "      <td>-464468.425375</td>\n",
       "      <td>3072</td>\n",
       "      <td>9.350809e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7mer</td>\n",
       "      <td>-462878.934210</td>\n",
       "      <td>49152</td>\n",
       "      <td>1.024062e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1mer</td>\n",
       "      <td>-495582.659663</td>\n",
       "      <td>12</td>\n",
       "      <td>9.911893e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CpG</td>\n",
       "      <td>-479643.425319</td>\n",
       "      <td>18</td>\n",
       "      <td>9.593229e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3mer</td>\n",
       "      <td>-477516.727115</td>\n",
       "      <td>192</td>\n",
       "      <td>9.554175e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5mer</td>\n",
       "      <td>-475512.667354</td>\n",
       "      <td>3072</td>\n",
       "      <td>9.571693e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7mer</td>\n",
       "      <td>-473870.160530</td>\n",
       "      <td>49152</td>\n",
       "      <td>1.046044e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  log_likelihood  n_param           AIC\n",
       "0  1mer  -483499.622290       12  9.670232e+05\n",
       "1   CpG  -468484.357064       18  9.370047e+05\n",
       "2  3mer  -466394.156015      192  9.331723e+05\n",
       "3  5mer  -464468.425375     3072  9.350809e+05\n",
       "4  7mer  -462878.934210    49152  1.024062e+06\n",
       "5  1mer  -495582.659663       12  9.911893e+05\n",
       "6   CpG  -479643.425319       18  9.593229e+05\n",
       "7  3mer  -477516.727115      192  9.554175e+05\n",
       "8  5mer  -475512.667354     3072  9.571693e+05\n",
       "9  7mer  -473870.160530    49152  1.046044e+06"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
