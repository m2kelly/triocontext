{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutation signatures for all k-mers\n",
    "\n",
    "The aim of this notebook is to compute the probability of the different k-mer changes through the approach described by Frigola et al. (2017). The signature probability is defined by the number of mutations found for a particular alteration taking into account its context, divided by the number of sites with the same reference k-mer. More information in the Materials and Methods section.\n",
    "\n",
    "---\n",
    "\n",
    "## Output\n",
    "\n",
    "The output of the notebook are files of the form ``kmer_signatures.txt`` that contains for each kmer the probability to mutate into the three possibles alternatives.\n",
    "\n",
    "An intermediate output (goes to data folder) contains the abundance of k-mers in the autosomal genome (or the CCDS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "from pyfasta import Fasta\n",
    "import pandas as pd\n",
    "from bgreference import hg19\n",
    "import math\n",
    "import pybedtools\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "\n",
    "Files in **data** directory.\n",
    "\n",
    "- *kmer_freq_file*: file that contains the counts of k-mers, which will be used for normalization\n",
    "**This last file is computed in this notebook, if still is not available**\n",
    "\n",
    "Files in **non_provided_data/mutations** directory.\n",
    "\n",
    "- *germinal_ultimate_dataset.bed.gz*: file that contains the autosomal *de novo* mutations (DNM) from 7 different datasets.\n",
    "\n",
    "Files in **genomes** directory.\n",
    "\n",
    "- *hg19.fa*: file with the genome hg19 from UCSC in fasta format.\n",
    "\n",
    "### Other inputs\n",
    "\n",
    "- mutations_path: base directory where the files with the mutations are located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Other\n",
    "mutations_path = 'non_provided_data/mutations/'\n",
    "\n",
    "# Load the hg19 genome\n",
    "f = Fasta('genomes/hg19/hg19.fa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "All the functions needed for this notebook are coded below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_version_ensembl(x, colname):\n",
    "    \"\"\"\n",
    "    Remove version from the ensembl ID\n",
    "\n",
    "    Args:\n",
    "        x: dataframe row\n",
    "        colname: column name\n",
    "\n",
    "    Returns:\n",
    "        str. Text before a '.'\n",
    "\n",
    "    \"\"\"\n",
    "    ensembl_id = x[colname]\n",
    "    ensembl_id_only = ensembl_id.split('.')[0]\n",
    "\n",
    "    return ensembl_id_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_kmer_alt(x,k):\n",
    "    \"\"\"\n",
    "    Compute the alternate kmer sequence from a DataFrame row or a dict \n",
    "    with the reference kmer and the alternated nucleotide\n",
    "    \"\"\"\n",
    "    my_alt = x['alt']\n",
    "    my_kmer = x['ref_kmer']\n",
    "\n",
    "    my_alt_kmer = my_kmer[0:(k//2)] + my_alt + my_kmer[(k//2)+1:]\n",
    "    \n",
    "    return my_alt_kmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_kmer_dict(k):\n",
    "    \"\"\"\n",
    "    Construct a dictionary where the values are the combinations\n",
    "    \"\"\"\n",
    "    \n",
    "    characters = 'ACGT'\n",
    "    nucleotides = ['A', 'C', 'T', 'G']\n",
    "    from itertools import product   \n",
    "    kmers = sorted([''.join(x) for x in product(characters, repeat=k)])\n",
    "    kmers_dict = dict()\n",
    "\n",
    "    for my_kmer in kmers:\n",
    "        mid_nucl = my_kmer[(k//2):(k//2)+1]\n",
    "\n",
    "        for my_nucleotide in nucleotides:\n",
    "            if my_nucleotide != mid_nucl:\n",
    "                my_alt_kmer = my_kmer[0:(k//2)] + my_nucleotide + my_kmer[(k//2)+1:]\n",
    "\n",
    "                kmers_dict[(my_kmer, my_alt_kmer)] = 0\n",
    "                \n",
    "    return kmers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_CpG_dict():\n",
    "    \"\"\"\n",
    "    Construct a dictionary where the values are the combinations\n",
    "    \"\"\"\n",
    "    \n",
    "    nucleotides = ['A', 'C', 'T', 'G']\n",
    "    kmers = ['A', 'T', 'nonCpG', 'CpG', 'GpC', 'nonGpC']\n",
    "    kmers_dict = dict()\n",
    "\n",
    "    for my_kmer in kmers:\n",
    "        if len(my_kmer) == 1:\n",
    "            mid_nucl = my_kmer\n",
    "        elif len(my_kmer) == 3:\n",
    "            mid_nucl = my_kmer[0]\n",
    "        else:\n",
    "            mid_nucl = my_kmer[3]\n",
    "\n",
    "        for my_nucleotide in nucleotides:\n",
    "            if my_nucleotide != mid_nucl:\n",
    "                kmers_dict[(my_kmer, my_nucleotide)] = 0\n",
    "                \n",
    "    return kmers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmer_generator(characters,k):\n",
    "    \"\"\"\n",
    "    Function that generates all DNA k-mers (alphabetically sorted) giving\n",
    "    a k-mer length and retrieves a dictionary with them as keys and 0 values.\n",
    "    \n",
    "    INPUT: A collection of at most 10 symbols defining an ordered alphabet, and a positive integer n (n<=10).\n",
    "    OUTPUT: A dictionary with all strings of length n that can be formed from the alphabet, ordered lexicographically\n",
    "    (use the standard order of symbols in the English alphabet) as keys and 0 as value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # To obtain the cartesian product (permutations including repetitions).\n",
    "    from itertools import product   \n",
    "    kmers = sorted([''.join(x) for x in product(characters, repeat=k)])\n",
    "    return(dict((kmer,0) for kmer in kmers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmer_abundance_autosomes(k,f):\n",
    "    \"\"\"\n",
    "    Function that compute the counts of k-mers in the autosomal hg19 reference genome.\n",
    "    \n",
    "    Args:\n",
    "        k: k-mer length\n",
    "        f: hg19 in Fasta\n",
    "\n",
    "    Returns:\n",
    "        :class:`~pandas.DataFrame`. Table with each k-mer and its abundace in the autosomal genome. \n",
    "    \"\"\"\n",
    "\n",
    "    # Create the dictionary\n",
    "    kmer_count = kmer_generator('ACGT',k)\n",
    "    # For each chromosome\n",
    "    for chromosome in range(1,23):\n",
    "        chrom = 'chr' + str(chromosome)\n",
    "        ## Get the length of the chromosome\n",
    "        length = len(str(f[chrom]))\n",
    "        ## Iterate over the sequence by kmers.\n",
    "        for i in range(length-(k-1)):\n",
    "            my_kmer = f[chrom][i:i+k]\n",
    "            try:\n",
    "                kmer_count[my_kmer.upper()] += 1\n",
    "            except:\n",
    "                None\n",
    "    \n",
    "    # Return a data.frame with the counts.\n",
    "    counts_df = pd.DataFrame({'kmer' : list(kmer_count.keys()) , 'count' : list(kmer_count.values()) })\n",
    "    counts_df = counts_df[['kmer', 'count']]\n",
    "    return(counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def signature(k, mutation_df, count_file, sampleID):\n",
    "    \n",
    "    my_probs_df = pd.DataFrame()\n",
    "    my_probs_df['mutation'] = list(create_kmer_dict(k).keys())\n",
    "    \n",
    "    ## Trinucleotide counts\n",
    "    k_freq_df = pd.read_csv(count_file, sep='\\t', header=None, low_memory=False)\n",
    "    k_freq_df.columns = ['kmer', 'count']\n",
    "    ## Compute the kmer changes (XYX -> XZX) of each alteration\n",
    "    mutation_df['ref_kmer'] = mutation_df.apply(lambda x: hg19(x['chr'], x['start']+1-(k//2),1+2*(k//2)), axis=1)\n",
    "    mutation_df['alt_kmer'] = mutation_df.apply(lambda x: compute_kmer_alt(x, k), axis=1)\n",
    "    mutation_df['mutation'] = list(zip(mutation_df.ref_kmer, mutation_df.alt_kmer))\n",
    "    \n",
    "    kmer_dict = create_kmer_dict(k)\n",
    "\n",
    "    # Compute the counts of each triplet alteration\n",
    "    for my_count in mutation_df['mutation'].value_counts().iteritems():\n",
    "        if my_count[0] in my_probs_df['mutation'].tolist():\n",
    "            kmer_dict[my_count[0]] = my_count[1]\n",
    "            \n",
    "    # Divide each count by the counts of the reference kmer\n",
    "    for my_kmer in kmer_dict.keys():\n",
    "        my_ref_kmer = my_kmer[0]\n",
    "        total_count = k_freq_df[k_freq_df['kmer'] == my_ref_kmer]['count'].values[0]\n",
    "        kmer_dict[my_kmer] = kmer_dict[my_kmer]/total_count\n",
    "        \n",
    "\n",
    "    column_name = 'Probability_' + str(sampleID)\n",
    "    my_results_df = pd.DataFrame({'mutation' : list(kmer_dict.keys()) , column_name : list(kmer_dict.values()) })\n",
    "    my_probs_df = pd.merge(my_probs_df, my_results_df, on='mutation')\n",
    "    return(my_probs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_CpG_site(x):\n",
    "    \"\"\"\n",
    "    Compute if mutation falls on CpG site (or CpG sites where G is the mutated position,\n",
    "    they are CpG sites in the other strand. We call them GpC, though it is not a good term).\n",
    "    \"\"\"\n",
    "    my_ref = x['nt']\n",
    "    my_pre = x['pre']\n",
    "    my_post = x['post']\n",
    "    if my_ref == 'C' and my_post == 'G':\n",
    "        my_site = 'CpG'\n",
    "    elif my_ref == 'G' and my_pre == 'C':\n",
    "        my_site = 'GpC'\n",
    "    elif my_ref == 'C' and my_post != 'G':\n",
    "        my_site = 'nonCpG'\n",
    "    elif my_ref == 'G' and my_pre != 'C':\n",
    "        my_site = 'nonGpC'\n",
    "    elif my_ref == 'A':\n",
    "        my_site = 'A'\n",
    "    elif my_ref == 'T':\n",
    "        my_site = 'T'\n",
    "    return my_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def signature_CpG(k, mutation_df, count_file, sampleID):\n",
    "\n",
    "    my_probs_df = pd.DataFrame()\n",
    "    my_probs_df['mutation'] = list(create_CpG_dict().keys())\n",
    "    \n",
    "    ## Trinucleotide counts\n",
    "    CpG_df = pd.read_csv(count_file, sep='\\t', header=None, low_memory=False)\n",
    "    CpG_df.columns = ['kmer', 'count']\n",
    "    \n",
    "    ## Compute the kmer changes (XYX -> XZX) of each alteration\n",
    "    mutation_df['ref_kmer'] = mutation_df.apply(lambda x: hg19(x['chr'], x['start']+1-(k//2),1+2*(k//2)), axis=1)\n",
    "    mutation_df[['pre', 'nt', 'post']] = mutation_df['ref_kmer'].apply(lambda x: pd.Series(list(x)))\n",
    "    mutation_df['site'] = mutation_df.apply(lambda x: compute_CpG_site(x), axis=1)\n",
    "    mutation_df['mutation'] = list(zip(mutation_df.site, mutation_df.alt))\n",
    "    \n",
    "    kmer_dict = create_CpG_dict()\n",
    "\n",
    "    # Compute the counts of each triplet alteration\n",
    "    for my_count in mutation_df['mutation'].value_counts().iteritems():\n",
    "        if my_count[0] in my_probs_df['mutation'].tolist():\n",
    "            kmer_dict[my_count[0]] = my_count[1]\n",
    "    \n",
    "    # Divide each count by the counts of the reference kmer\n",
    "    for my_kmer in kmer_dict.keys():\n",
    "        my_ref_kmer = my_kmer[0]\n",
    "        total_count = CpG_df[CpG_df['kmer'] == my_ref_kmer]['count'].values[0]\n",
    "        kmer_dict[my_kmer] = kmer_dict[my_kmer]/total_count\n",
    "\n",
    "    column_name = 'Probability_' + str(sampleID)\n",
    "    my_results_df = pd.DataFrame({'mutation' : list(kmer_dict.keys()) , column_name : list(kmer_dict.values()) })\n",
    "    my_probs_df = pd.merge(my_probs_df, my_results_df, on='mutation')\n",
    "    return(my_probs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmer_abundance_window(k, middle_exon_coords, middle_distance_threshold):\n",
    "    \"\"\"\n",
    "    \n",
    "    Args:\n",
    "        k: k-mer length\n",
    "        middle_exon_coords:\n",
    "        middle_distance_threshold:\n",
    "\n",
    "    Returns:\n",
    "        :class:`~pandas.DataFrame`. \n",
    "    \"\"\"\n",
    "    \n",
    "    middle_exon_coords['exon_size'] = (middle_exon_coords['end'] - middle_exon_coords['start'])\n",
    "    middle_exon_coords['exon_middle_start'] = (middle_exon_coords['start'] + middle_exon_coords['exon_size']/2)\n",
    "    middle_exon_coords['exon_middle_start'] = middle_exon_coords.apply(lambda x:\n",
    "                                                                    math.floor(x['exon_middle_start']),\n",
    "                                                                    axis=1)\n",
    "\n",
    "    ## Process coordinates\n",
    "    middle_exon_coords['exon_middle_end'] = middle_exon_coords['exon_middle_start'] + 1\n",
    "    middle_exon_coords['region_start'] = middle_exon_coords['exon_middle_start'] - middle_distance_threshold\n",
    "    middle_exon_coords['region_end'] = middle_exon_coords['exon_middle_end'] + middle_distance_threshold\n",
    "    sub_exons_coords = middle_exon_coords[['chr', 'region_start', 'region_end', 'ensembl', 'exon_size',\n",
    "                                           'exon_middle_start', 'exon_middle_end']]\n",
    "\n",
    "    # Create the dictionary\n",
    "    kmer_count = kmer_generator('ACGT',k)\n",
    "    \n",
    "    # Create the dictionary\n",
    "    for my_row in sub_exons_coords.values.tolist():\n",
    "    \n",
    "        ## Get coordinates\n",
    "        my_chr = my_row[0]\n",
    "        my_start = int(my_row[1])\n",
    "        my_end = int(my_row[2])\n",
    "        n_bases = my_end - my_start\n",
    "    \n",
    "        ## Get sequence\n",
    "        my_exon_bases = hg19(my_chr, my_start+1-(k//2), size=n_bases+2*(k//2))\n",
    "        ## Divide sequence into k-mers\n",
    "        my_kmers = [my_exon_bases[i:i+k] for i in range(len(my_exon_bases)-(k-1))]\n",
    "        \n",
    "        ## Count each k-mer\n",
    "        for my_kmer in my_kmers:\n",
    "            try:\n",
    "                kmer_count[my_kmer.upper()] += 1\n",
    "            except:\n",
    "                None\n",
    "    \n",
    "    # Return a data.frame with the counts.\n",
    "    counts_df = pd.DataFrame({'kmer' : list(kmer_count.keys()) , 'count' : list(kmer_count.values()) })\n",
    "    counts_df = counts_df[['kmer', 'count']]\n",
    "    return(counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmer_abundance_coords(k, coords):\n",
    "    \"\"\"\n",
    "    \n",
    "    Args:\n",
    "        k: k-mer length\n",
    "        coords: coordinates\n",
    "\n",
    "    Returns:\n",
    "        :class:`~pandas.DataFrame`. \n",
    "    \"\"\"\n",
    "\n",
    "    # Create the dictionary\n",
    "    kmer_count = kmer_generator('ACGT',k)\n",
    "    \n",
    "    # Create the dictionary\n",
    "    for my_row in coords.values.tolist():\n",
    "    \n",
    "        ## Get coordinates\n",
    "        my_chr = my_row[0]\n",
    "        my_start = int(my_row[1])\n",
    "        my_end = int(my_row[2])\n",
    "        n_bases = my_end - my_start\n",
    "    \n",
    "        ## Get sequence\n",
    "        my_exon_bases = hg19(my_chr, my_start+1-(k//2), size=n_bases+2*(k//2))\n",
    "        ## Divide sequence into k-mers\n",
    "        my_kmers = [my_exon_bases[i:i+k] for i in range(len(my_exon_bases)-(k-1))]\n",
    "        \n",
    "        ## Count each k-mer\n",
    "        for my_kmer in my_kmers:\n",
    "            try:\n",
    "                kmer_count[my_kmer.upper()] += 1\n",
    "            except:\n",
    "                None\n",
    "    \n",
    "    # Return a data.frame with the counts.\n",
    "    counts_df = pd.DataFrame({'kmer' : list(kmer_count.keys()) , 'count' : list(kmer_count.values()) })\n",
    "    counts_df = counts_df[['kmer', 'count']]\n",
    "    return(counts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compute the nucleotide counts at the autosomal genome\n",
    "\n",
    "We retrieve the hg19 autosomal genome and compute the counts of the 4 nucleotides.\n",
    "\n",
    "**IGNORE THIS BLOCK OF CODE IF THET ARE ALREADY COMPUTED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 1\n",
    "\n",
    "results = kmer_abundance_autosomes(k, f)\n",
    "filename = str(k) + 'mer.txt' \n",
    "results.to_csv(path.join('data', filename), sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compute the trinucleotide counts at the autosomal genome\n",
    "\n",
    "We retrieve the hg19 autosomal genome and compute the counts of the 64 possible trinucleotides.\n",
    "\n",
    "**IGNORE THIS BLOCK OF CODE IF THET ARE ALREADY COMPUTED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "\n",
    "results = kmer_abundance_autosomes(k, f)\n",
    "filename = str(k) + 'mer.txt' \n",
    "results.to_csv(path.join('data', filename), sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the CpG counts at the autosomal genome\n",
    "\n",
    "Based on the trinucleotide counts.\n",
    "\n",
    "**IGNORE THIS BLOCK OF CODE IF THET ARE ALREADY COMPUTED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "filename =  'data/' + str(k) + 'mer.txt' \n",
    "\n",
    "k_freq_df = pd.read_csv(filename, sep='\\t', header=None, low_memory=False)\n",
    "k_freq_df.columns = ['kmer', 'count']\n",
    "k_freq_df[['pre', 'nt', 'post']] = k_freq_df['kmer'].apply(lambda x: pd.Series(list(x)))\n",
    "    \n",
    "CpG_dict = {}\n",
    "CpG_dict['A'] = k_freq_df.loc[k_freq_df['nt'] == 'A', 'count'].sum()\n",
    "CpG_dict['T'] = k_freq_df.loc[k_freq_df['nt'] == 'T', 'count'].sum()\n",
    "CpG_dict['nonCpG'] = k_freq_df.loc[(k_freq_df['nt'] == 'C') & (k_freq_df['post'] != 'G'), 'count'].sum()\n",
    "CpG_dict['CpG'] = k_freq_df.loc[(k_freq_df['nt'] == 'C') & (k_freq_df['post'] == 'G'), 'count'].sum()\n",
    "CpG_dict['nonGpC'] = k_freq_df.loc[(k_freq_df['nt'] == 'G') & (k_freq_df['pre'] != 'C'), 'count'].sum()\n",
    "CpG_dict['GpC'] = k_freq_df.loc[(k_freq_df['nt'] == 'G') & (k_freq_df['pre'] == 'C'), 'count'].sum()\n",
    "CpG_df = pd.DataFrame(list(CpG_dict.items()), columns=['kmer', 'count'])\n",
    "\n",
    "CpG_df.to_csv(path.join('data', 'CpGmer.txt'), sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compute the pentanucleotide counts at the autosomal genome\n",
    "\n",
    "We retrieve the hg19 autosomal genome and compute the counts of the 1024 possible pentanucleotides.\n",
    "\n",
    "**IGNORE THIS BLOCK OF CODE IF THET ARE ALREADY COMPUTED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "results = kmer_abundance_autosomes(k, f)\n",
    "filename = str(k) + 'mer.txt' \n",
    "results.to_csv(path.join('data', filename), sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compute the heptanucleotide counts at the autosomal genome\n",
    "\n",
    "We retrieve the hg19 autosomal genome and compute the counts of the 16,384 possible heptanucleotides.\n",
    "\n",
    "**IGNORE THIS BLOCK OF CODE IF THET ARE ALREADY COMPUTED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 7\n",
    "\n",
    "results = kmer_abundance_autosomes(k, f)\n",
    "filename = str(k) + 'mer.txt' \n",
    "results.to_csv(path.join('data', filename), sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compute the nonanucleotide counts at the autosomal genome\n",
    "\n",
    "We retrieve the hg19 autosomal genome and compute the counts of the possible nonanucleotides.\n",
    "\n",
    "**IGNORE THIS BLOCK OF CODE IF THET ARE ALREADY COMPUTED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 9\n",
    "\n",
    "results = kmer_abundance_autosomes(k, f)\n",
    "filename = str(k) + 'mer.txt' \n",
    "results.to_csv(path.join('data', filename), sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the trinucleotide counts at the entire CCDS exons and the respective introns\n",
    "\n",
    "**IGNORE THIS BLOCK OF CODE IF THET ARE ALREADY COMPUTED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load CCDS exon coords\n",
    "exons_file = 'data/coordinates/exons_CCDS.bed.gz'\n",
    "exons_coords_df = pd.read_csv(exons_file, sep=\"\\t\", header=None, low_memory=False)\n",
    "exons_coords_df.columns = ['chr', 'start', 'end', 'ensembl', 'symbol', 'strand']\n",
    "exons_coords_df = exons_coords_df[['chr', 'start', 'end', 'ensembl']]\n",
    "exons_coords_df['ensembl'] = exons_coords_df.apply(lambda x: remove_version_ensembl(x, 'ensembl'), axis=1)\n",
    "exons_coords_df.columns = ['chr', 'start', 'end', 'ensembl']\n",
    "\n",
    "# Load respective intron coords\n",
    "introns_file = 'data/coordinates/introns_CCDS.bed.gz'\n",
    "introns_coords_df = pd.read_csv(introns_file, sep=\"\\t\", header=None, low_memory=False)\n",
    "introns_coords_df.columns = ['chr', 'start', 'end', 'ensembl', 'symbol', 'strand']\n",
    "introns_coords_df = introns_coords_df[['chr', 'start', 'end', 'ensembl']]\n",
    "introns_coords_df['ensembl'] = introns_coords_df.apply(lambda x: remove_version_ensembl(x, 'ensembl'), axis=1)\n",
    "introns_coords_df.columns = ['chr', 'start', 'end', 'ensembl']\n",
    "\n",
    "# Merge them\n",
    "frames = [exons_coords_df, introns_coords_df]\n",
    "all_coords_df = pd.concat(frames)\n",
    "\n",
    "k = 3\n",
    "\n",
    "results = kmer_abundance_coords(k, all_coords_df)\n",
    "filename = str(k) + 'mer_CCDS.txt' \n",
    "results.to_csv(path.join('data', filename), sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the signature for the golden dataset (Goldmann 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the mutations\n",
    "mutations_file = mutations_path + 'germinal_ultimate_dataset.bed.gz'\n",
    "mutations_df = pd.read_csv(mutations_file, sep=\"\\t\", header=None)\n",
    "mutations_df.columns = ['chr', 'start', 'end', 'ref', 'alt', 'sample', 'type', 'class']\n",
    "mutations_df = mutations_df[mutations_df['type'] == 'subs']\n",
    "mutations_df = mutations_df[['chr', 'start', 'end', 'ref', 'alt', 'sample', 'type']]\n",
    "mutations_df = mutations_df[mutations_df['sample'] == 'Goldmann2018']\n",
    "\n",
    "sampleID = 'germinal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Mutation signature 1-mer with DNM, WG counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 1\n",
    "\n",
    "k_mer_count_file = 'data/' + str(k) + 'mer.txt'\n",
    "\n",
    "results = signature(k, mutations_df, k_mer_count_file, sampleID)\n",
    "filename = str(k) + 'mer_signatures_DNM_golden.txt' \n",
    "results.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Mutation signature 1-mer 9 classes with CpG with DNM, WG counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "\n",
    "k_mer_count_file = 'data/CpGmer.txt'\n",
    "\n",
    "results = signature_CpG(k, mutations_df, k_mer_count_file, sampleID)\n",
    "filename = 'CpG_signatures_DNM_golden.txt' \n",
    "results.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Mutation signature 3-mer with DNM, WG counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "\n",
    "k_mer_count_file = 'data/' + str(k) + 'mer.txt'\n",
    "\n",
    "results = signature(k, mutations_df, k_mer_count_file, sampleID)\n",
    "filename = str(k) + 'mer_signatures_DNM_golden.txt' \n",
    "results.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Mutation signature 5-mer with DNM, WG counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "k_mer_count_file = 'data/' + str(k) + 'mer.txt'\n",
    "\n",
    "results = signature(k, mutations_df, k_mer_count_file, sampleID)\n",
    "filename = str(k) + 'mer_signatures_DNM_golden.txt' \n",
    "results.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Mutation signature 7-mer with DNM, WG counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 7\n",
    "\n",
    "k_mer_count_file = 'data/' + str(k) + 'mer.txt'\n",
    "\n",
    "results = signature(k, mutations_df, k_mer_count_file, sampleID)\n",
    "filename = str(k) + 'mer_signatures_DNM_golden.txt' \n",
    "results.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the signature for the largest dataset (Halldorsson 2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the mutations\n",
    "mutations_file = mutations_path + 'germinal_ultimate_dataset.bed.gz'\n",
    "mutations_df = pd.read_csv(mutations_file, sep=\"\\t\", header=None)\n",
    "mutations_df.columns = ['chr', 'start', 'end', 'ref', 'alt', 'sample', 'type', 'class']\n",
    "mutations_df = mutations_df[mutations_df['type'] == 'subs']\n",
    "mutations_df = mutations_df[['chr', 'start', 'end', 'ref', 'alt', 'sample', 'type']]\n",
    "mutations_df = mutations_df[mutations_df['sample'] == 'Halldorsson2019']\n",
    "\n",
    "sampleID = 'germinal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Mutation signature 1-mer with DNM, WG counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 1\n",
    "\n",
    "k_mer_count_file = 'data/' + str(k) + 'mer.txt'\n",
    "\n",
    "results = signature(k, mutations_df, k_mer_count_file, sampleID)\n",
    "filename = str(k) + 'mer_signatures_DNM_Halldorsson.txt' \n",
    "results.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Mutation signature 1-mer 9 classes with CpG with DNM, WG counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "\n",
    "k_mer_count_file = 'data/CpGmer.txt'\n",
    "\n",
    "results = signature_CpG(k, mutations_df, k_mer_count_file, sampleID)\n",
    "filename = 'CpG_signatures_DNM_Halldorsson.txt' \n",
    "results.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Mutation signature 3-mer with DNM, WG counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "\n",
    "k_mer_count_file = 'data/' + str(k) + 'mer.txt'\n",
    "\n",
    "results = signature(k, mutations_df, k_mer_count_file, sampleID)\n",
    "filename = str(k) + 'mer_signatures_DNM_Halldorsson.txt' \n",
    "results.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Mutation signature 5-mer with DNM, WG counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "k_mer_count_file = 'data/' + str(k) + 'mer.txt'\n",
    "\n",
    "results = signature(k, mutations_df, k_mer_count_file, sampleID)\n",
    "filename = str(k) + 'mer_signatures_DNM_Halldorsson.txt' \n",
    "results.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Mutation signature 7-mer with DNM, WG counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 7\n",
    "\n",
    "k_mer_count_file = 'data/' + str(k) + 'mer.txt'\n",
    "\n",
    "results = signature(k, mutations_df, k_mer_count_file, sampleID)\n",
    "filename = str(k) + 'mer_signatures_DNM_Halldorsson.txt' \n",
    "results.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the DNM signature for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the mutations\n",
    "mutations_file = mutations_path + 'germinal_ultimate_dataset.bed.gz'\n",
    "mutations_df = pd.read_csv(mutations_file, sep=\"\\t\", header=None)\n",
    "mutations_df.columns = ['chr', 'start', 'end', 'ref', 'alt', 'sample', 'type', 'class']\n",
    "mutations_df = mutations_df[mutations_df['type'] == 'subs']\n",
    "mutations_df = mutations_df[['chr', 'start', 'end', 'ref', 'alt', 'sample', 'type']]\n",
    "\n",
    "sampleID = 'germinal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Mutation signature 1-mer with DNM, WG counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 1\n",
    "\n",
    "k_mer_count_file = 'data/' + str(k) + 'mer.txt'\n",
    "\n",
    "results = signature(k, mutations_df, k_mer_count_file, sampleID)\n",
    "filename = str(k) + 'mer_signatures_DNM_new.txt' \n",
    "results.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Mutation signature 1-mer 9 classes with CpG with DNM, WG counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "\n",
    "k_mer_count_file = 'data/CpGmer.txt'\n",
    "\n",
    "results = signature_CpG(k, mutations_df, k_mer_count_file, sampleID)\n",
    "filename = 'CpG_signatures_DNM_new.txt' \n",
    "results.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Mutation signature 3-mer with DNM, WG counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "\n",
    "k_mer_count_file = 'data/' + str(k) + 'mer.txt'\n",
    "\n",
    "results = signature(k, mutations_df, k_mer_count_file, sampleID)\n",
    "filename = str(k) + 'mer_signatures_DNM_new.txt' \n",
    "results.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Mutation signature 5-mer with DNM, WG counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "k_mer_count_file = 'data/' + str(k) + 'mer.txt'\n",
    "\n",
    "results = signature(k, mutations_df, k_mer_count_file, sampleID)\n",
    "filename = str(k) + 'mer_signatures_DNM_new.txt' \n",
    "results.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Mutation signature 7-mer with DNM, WG counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 7\n",
    "\n",
    "k_mer_count_file = 'data/' + str(k) + 'mer.txt'\n",
    "\n",
    "results = signature(k, mutations_df, k_mer_count_file, sampleID)\n",
    "filename = str(k) + 'mer_signatures_DNM_new.txt' \n",
    "results.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutation signature 3-mer with DNM, CCDS exons and introns (only the genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load CCDS exon coords\n",
    "exons_file = 'data/coordinates/exons_CCDS.bed.gz'\n",
    "exons_coords_df = pd.read_csv(exons_file, sep=\"\\t\", header=None, low_memory=False)\n",
    "exons_coords_df.columns = ['chr', 'start', 'end', 'ensembl', 'symbol', 'strand']\n",
    "exons_coords_df = exons_coords_df[['chr', 'start', 'end', 'ensembl']]\n",
    "exons_coords_df['ensembl'] = exons_coords_df.apply(lambda x: remove_version_ensembl(x, 'ensembl'), axis=1)\n",
    "exons_coords_df.columns = ['chr', 'start', 'end', 'ensembl']\n",
    "\n",
    "# Load respective intron coords\n",
    "introns_file = 'data/coordinates/introns_CCDS.bed.gz'\n",
    "introns_coords_df = pd.read_csv(introns_file, sep=\"\\t\", header=None, low_memory=False)\n",
    "introns_coords_df.columns = ['chr', 'start', 'end', 'ensembl', 'symbol', 'strand']\n",
    "introns_coords_df = introns_coords_df[['chr', 'start', 'end', 'ensembl']]\n",
    "introns_coords_df['ensembl'] = introns_coords_df.apply(lambda x: remove_version_ensembl(x, 'ensembl'), axis=1)\n",
    "introns_coords_df.columns = ['chr', 'start', 'end', 'ensembl']\n",
    "\n",
    "# Merge them\n",
    "frames = [exons_coords_df, introns_coords_df]\n",
    "all_coords_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total amount of mutations at the middle exon-centered sequences is 291137\n"
     ]
    }
   ],
   "source": [
    "# Convert mutations into bed to intersect values\n",
    "mutations_bed = pybedtools.BedTool.from_dataframe(mutations_df)\n",
    "\n",
    "region_coords_bed = pybedtools.BedTool.from_dataframe(all_coords_df)\n",
    "\n",
    "# Filter mutations by the full region of interest\n",
    "my_bed = region_coords_bed.intersect(mutations_bed, wao=True)\n",
    "\n",
    "sub_mutations_df = pd.read_table(my_bed.fn, names = ['range_chr', 'range_start', 'range_end',\n",
    "                        'ensembl', 'mut_chr', 'mut_start', 'mut_end', 'mut_ref', 'mut_alt',\n",
    "                        'mut_sample', 'mut_type', 'overlap_bp'],  sep=\"\\s+\", index_col=False)\n",
    "sub_mutations_df = sub_mutations_df[sub_mutations_df['overlap_bp'] != 0]\n",
    "sub_mutations_df = sub_mutations_df[['mut_chr', 'mut_start', 'mut_end', 'mut_ref', 'mut_alt', 'mut_sample',\n",
    "                                     'mut_type']]\n",
    "sub_mutations_df.columns = ['chr', 'start', 'end', 'ref', 'alt', 'sample', 'type']\n",
    "print(\"The total amount of mutations at the middle exon-centered sequences is \" +\n",
    "        str(len(sub_mutations_df.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "\n",
    "k_mer_count_file = 'data/' + str(k) + 'mer_CCDS.txt'\n",
    "\n",
    "results = signature(k, sub_mutations_df, k_mer_count_file, sampleID)\n",
    "filename = str(k) + 'mer_signatures_DNM_CCDS.txt' \n",
    "results.to_csv(path.join('results', filename), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compute the 3-mer signature for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the mutations\n",
    "mutations_file = mutations_path + 'germinal_ultimate_dataset.bed.gz'\n",
    "mutations_df = pd.read_csv(mutations_file, sep=\"\\t\", header=None)\n",
    "mutations_df.columns = ['chr', 'start', 'end', 'ref', 'alt', 'sample', 'type', 'class']\n",
    "mutations_df = mutations_df[mutations_df['type'] == 'subs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "count_file = 'data/' + str(k) + 'mer.txt'\n",
    "\n",
    "my_probs_df = pd.DataFrame()\n",
    "my_probs_df['mutation'] = list(create_kmer_dict(k).keys())\n",
    "\n",
    "## Trinucleotide counts\n",
    "k_freq_df = pd.read_csv(count_file, sep='\\t', header=None, low_memory=False)\n",
    "k_freq_df.columns = ['kmer', 'count']\n",
    "\n",
    "studies_list = mutations_df['sample'].unique().tolist()\n",
    "\n",
    "for my_study in studies_list:\n",
    "    sub_mutations_df = mutations_df[mutations_df['sample'] == my_study].copy()\n",
    "    sub_mutations_df['ref_kmer'] = sub_mutations_df.apply(lambda x: hg19(x['chr'], x['start']+1-(k//2),1+2*(k//2)),\n",
    "                                axis=1)\n",
    "    sub_mutations_df['alt_kmer'] = sub_mutations_df.apply(lambda x: compute_kmer_alt(x, k), axis=1)\n",
    "    sub_mutations_df['mutation'] = list(zip(sub_mutations_df.ref_kmer, sub_mutations_df.alt_kmer))\n",
    "\n",
    "    kmer_dict = create_kmer_dict(k)\n",
    "\n",
    "    # Compute the counts of each triplet alteration\n",
    "    for my_count in sub_mutations_df['mutation'].value_counts().iteritems():\n",
    "        if my_count[0] in my_probs_df['mutation'].tolist():\n",
    "            kmer_dict[my_count[0]] = my_count[1]\n",
    "\n",
    "    # Divide each count by the counts of the reference trinucleotide\n",
    "    for my_kmer in kmer_dict.keys():\n",
    "        my_ref_kmer = my_kmer[0]\n",
    "        total_count = k_freq_df[k_freq_df['kmer'] == my_ref_kmer]['count'].values[0]\n",
    "        kmer_dict[my_kmer] = kmer_dict[my_kmer]/total_count\n",
    "    \n",
    "    column_name = 'Probability_' + str(my_study)\n",
    "    study_probs_df = pd.DataFrame({'mutation' : list(kmer_dict.keys()) , column_name : list(kmer_dict.values()) })\n",
    "    my_probs_df = pd.merge(my_probs_df, study_probs_df, on='mutation')\n",
    "\n",
    "my_probs_df.to_csv(path.join('results', 'ALL_signatures.txt'), header=True, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
